package resolver

// This file will be automatically regenerated based on the schema, any resolver
// implementations
// will be copied through when generating and any unknown code will be moved to the end.
// Code generated by github.com/99designs/gqlgen version v0.17.85

import (
	"context"

	"github.com/google/uuid"
	"github.com/xzzpig/rclone-sync/internal/api/graphql/dataloader"
	"github.com/xzzpig/rclone-sync/internal/api/graphql/generated"
	"github.com/xzzpig/rclone-sync/internal/api/graphql/model"
	"github.com/xzzpig/rclone-sync/internal/api/graphql/subscription"
	"github.com/xzzpig/rclone-sync/internal/core/logger"
)

// Task is the resolver for the task field.
func (r *jobResolver) Task(ctx context.Context, obj *model.Job) (*model.Task, error) {
	// Use dataloader with pre-resolved TaskID to avoid N+1 queries
	loaders := dataloader.For(ctx)
	entTask, err := loaders.TaskLoader.Load(ctx, obj.TaskID)
	if err != nil {
		return nil, err
	}

	return entTaskToModel(entTask), nil
}

// Logs is the resolver for the logs field.
func (r *jobResolver) Logs(ctx context.Context, obj *model.Job, pagination *model.PaginationInput) (*model.JobLogConnection, error) {
	// Default pagination values
	limit := 20
	offset := 0
	if pagination != nil {
		if pagination.Limit != nil {
			limit = *pagination.Limit
		}
		if pagination.Offset != nil {
			offset = *pagination.Offset
		}
	}

	// Use JobService to list logs for this job
	entLogs, totalCount, err := r.deps.JobService.ListJobLogsByJobPaginated(ctx, obj.ID, limit, offset)
	if err != nil {
		return nil, err
	}

	// Convert ent logs to model logs
	items := make([]*model.JobLog, len(entLogs))
	for i, l := range entLogs {
		items[i] = entJobLogToModel(l)
	}

	// Build page info
	hasNextPage := offset+len(items) < totalCount
	hasPreviousPage := offset > 0

	return &model.JobLogConnection{
		Items:      items,
		TotalCount: totalCount,
		PageInfo: &model.OffsetPageInfo{
			Limit:           limit,
			Offset:          offset,
			HasNextPage:     hasNextPage,
			HasPreviousPage: hasPreviousPage,
		},
	}, nil
}

// Progress is the resolver for the progress field.
func (r *jobResolver) Progress(ctx context.Context, obj *model.Job) (*model.JobProgressEvent, error) {
	// Get progress from SyncEngine - only returns non-nil for RUNNING jobs
	return r.deps.SyncEngine.GetJobProgress(obj.ID), nil
}

// Job is the resolver for the job field.
func (r *jobLogResolver) Job(ctx context.Context, obj *model.JobLog) (*model.Job, error) {
	// Use dataloader with pre-resolved JobID to avoid N+1 queries
	loaders := dataloader.For(ctx)
	entJob, err := loaders.JobLoader.Load(ctx, obj.JobID)
	if err != nil {
		return nil, err
	}

	return entJobToModel(entJob), nil
}

// List is the resolver for the list field.
func (r *jobQueryResolver) List(ctx context.Context, obj *model.JobQuery, taskID *uuid.UUID, connectionID *uuid.UUID, pagination *model.PaginationInput) (*model.JobConnection, error) {
	// Default pagination values
	limit := 20
	offset := 0
	if pagination != nil {
		if pagination.Limit != nil {
			limit = *pagination.Limit
		}
		if pagination.Offset != nil {
			offset = *pagination.Offset
		}
	}

	// Get total count
	totalCount, err := r.deps.JobService.CountJobs(ctx, taskID, connectionID)
	if err != nil {
		return nil, err
	}

	// Fetch jobs
	entJobs, err := r.deps.JobService.ListJobs(ctx, taskID, connectionID, limit, offset)
	if err != nil {
		return nil, err
	}

	// Convert ent jobs to model jobs
	items := make([]*model.Job, len(entJobs))
	for i, j := range entJobs {
		items[i] = entJobToModel(j)
	}

	// Build page info
	hasNextPage := offset+len(items) < totalCount
	hasPreviousPage := offset > 0

	return &model.JobConnection{
		Items:      items,
		TotalCount: totalCount,
		PageInfo: &model.OffsetPageInfo{
			Limit:           limit,
			Offset:          offset,
			HasNextPage:     hasNextPage,
			HasPreviousPage: hasPreviousPage,
		},
	}, nil
}

// Progress is the resolver for the progress field.
func (r *jobQueryResolver) Progress(ctx context.Context, obj *model.JobQuery, id uuid.UUID) (*model.JobProgressEvent, error) {
	// Get progress from SyncEngine - returns the cached JobProgressEvent directly
	return r.deps.SyncEngine.GetJobProgress(id), nil
}

// List is the resolver for the list field.
func (r *logQueryResolver) List(ctx context.Context, obj *model.LogQuery, connectionID uuid.UUID, taskID *uuid.UUID, jobID *uuid.UUID, level *model.LogLevel, pagination *model.PaginationInput) (*model.JobLogConnection, error) {
	// Default pagination values
	limit := 20
	offset := 0
	if pagination != nil {
		if pagination.Limit != nil {
			limit = *pagination.Limit
		}
		if pagination.Offset != nil {
			offset = *pagination.Offset
		}
	}

	// Convert level enum to string
	levelStr := ""
	if level != nil {
		levelStr = string(*level)
	}

	// Get total count
	totalCount, err := r.deps.JobService.CountJobLogs(ctx, &connectionID, taskID, jobID, levelStr)
	if err != nil {
		return nil, err
	}

	// Fetch logs
	entLogs, err := r.deps.JobService.ListJobLogs(ctx, &connectionID, taskID, jobID, levelStr, limit, offset)
	if err != nil {
		return nil, err
	}

	// Convert ent logs to model logs
	items := make([]*model.JobLog, len(entLogs))
	for i, l := range entLogs {
		items[i] = entJobLogToModel(l)
	}

	// Build page info
	hasNextPage := offset+len(items) < totalCount
	hasPreviousPage := offset > 0

	return &model.JobLogConnection{
		Items:      items,
		TotalCount: totalCount,
		PageInfo: &model.OffsetPageInfo{
			Limit:           limit,
			Offset:          offset,
			HasNextPage:     hasNextPage,
			HasPreviousPage: hasPreviousPage,
		},
	}, nil
}

// Job is the resolver for the job field.
func (r *queryResolver) Job(ctx context.Context) (*model.JobQuery, error) {
	return &model.JobQuery{}, nil
}

// Log is the resolver for the log field.
func (r *queryResolver) Log(ctx context.Context) (*model.LogQuery, error) {
	return &model.LogQuery{}, nil
}

// JobProgress is the resolver for the jobProgress field.
func (r *subscriptionResolver) JobProgress(ctx context.Context, taskID *uuid.UUID, connectionID *uuid.UUID) (<-chan *model.JobProgressEvent, error) {
	// Check if JobProgressBus is available
	if r.deps.JobProgressBus == nil {
		// Fallback: return an empty channel that immediately closes
		ch := make(chan *model.JobProgressEvent)
		close(ch)
		return ch, nil
	}

	// Create filter based on taskID and connectionID
	filter := subscription.JobProgressFilter(taskID, connectionID)

	// Subscribe to job progress events with the filter
	sub := r.deps.JobProgressBus.Subscribe(filter)

	// Create output channel that will be closed when context is done
	out := make(chan *model.JobProgressEvent)

	go func() {
		defer r.deps.JobProgressBus.Unsubscribe(sub.ID)
		defer close(out)

		for {
			select {
			case <-ctx.Done():
				// Client disconnected
				return
			case event, ok := <-sub.Events:
				if !ok {
					// Subscription closed
					return
				}
				select {
				case out <- event:
					// Event sent
				case <-ctx.Done():
					return
				}
			}
		}
	}()

	return out, nil
}

// TransferProgress is the resolver for the transferProgress field.
func (r *subscriptionResolver) TransferProgress(ctx context.Context, connectionID *uuid.UUID, taskID *uuid.UUID, jobID *uuid.UUID) (<-chan *model.TransferProgressEvent, error) {
	// Check if TransferProgressBus is available
	if r.deps.TransferProgressBus == nil {
		// Fallback: return an empty channel that immediately closes
		logger.Named("api.graphql.resolver.job").Warn("TransferProgressBus is not available, returning empty subscription channel")
		ch := make(chan *model.TransferProgressEvent)
		close(ch)
		return ch, nil
	}

	// Create filter based on connectionID, taskID, and jobID
	filter := subscription.TransferProgressFilter(connectionID, taskID, jobID)

	// Subscribe to transfer progress events with the filter
	sub := r.deps.TransferProgressBus.Subscribe(filter)

	// Create output channel that will be closed when context is done
	out := make(chan *model.TransferProgressEvent)

	go func() {
		defer r.deps.TransferProgressBus.Unsubscribe(sub.ID)
		defer close(out)

		for {
			select {
			case <-ctx.Done():
				// Client disconnected
				return
			case event, ok := <-sub.Events:
				if !ok {
					// Subscription closed
					return
				}
				select {
				case out <- event:
					// Event sent
				case <-ctx.Done():
					return
				}
			}
		}
	}()

	return out, nil
}

// Job returns generated.JobResolver implementation.
func (r *Resolver) Job() generated.JobResolver { return &jobResolver{r} }

// JobLog returns generated.JobLogResolver implementation.
func (r *Resolver) JobLog() generated.JobLogResolver { return &jobLogResolver{r} }

// JobQuery returns generated.JobQueryResolver implementation.
func (r *Resolver) JobQuery() generated.JobQueryResolver { return &jobQueryResolver{r} }

// LogQuery returns generated.LogQueryResolver implementation.
func (r *Resolver) LogQuery() generated.LogQueryResolver { return &logQueryResolver{r} }

type jobResolver struct{ *Resolver }
type jobLogResolver struct{ *Resolver }
type jobQueryResolver struct{ *Resolver }
type logQueryResolver struct{ *Resolver }
